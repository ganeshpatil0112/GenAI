{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a661a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning (the ability to improve performance over time), reasoning (the ability to analyze information and make decisions), problem-solving, understanding natural language, perception (such as vision and speech recognition), and even creativity. AI systems can range from simple algorithms performing specific tasks to complex models like deep learning networks that can analyze vast amounts of data and adapt their behavior accordingly. The goal of AI is to create systems that can perform tasks typically requiring human intelligence, ultimately enabling automation, improved decision-making, and new technological capabilities across various fields.\n"
     ]
    }
   ],
   "source": [
    "from euriai.langchain import create_chat_model\n",
    "\n",
    "chat_model = create_chat_model(\n",
    "    api_key=\"euri-1f3025f0ddab44e290bf86bed48790c9f4fd1325a59b42e49701607ebb5b9546\",\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"What is artificial intelligence?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b549e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.7\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show euriai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417599f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: euriai in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (1.0.32)\n",
      "Requirement already satisfied: requests in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from euriai) (2.32.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from euriai) (2.2.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from euriai) (6.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from requests->euriai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from requests->euriai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from requests->euriai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\scl\\anaconda3\\envs\\agentiai\\lib\\site-packages (from requests->euriai) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade euriai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3726491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from euriai.langchain import create_chat_model\n",
    "\n",
    "# Full streaming support\n",
    "chat_model = create_chat_model(api_key=\"euri-1f3025f0ddab44e290bf86bed48790c9f4fd1325a59b42e49701607ebb5b9546\")\n",
    "\n",
    "# Streaming response\n",
    "for chunk in chat_model.stream(\"Tell me a story about god Shri Krishna\"):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "# Async streaming\n",
    "import asyncio\n",
    "\n",
    "async def async_stream():\n",
    "    async for chunk in chat_model.astream(\"Tell me a story about god Shri Krishna\"):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "# asyncio.run(async_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langchain langchain-core langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560375a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast,re,math,os,sys\n",
    "os.environ[\"euri-api-key\"] =\"euri-1f3025f0ddab44e290bf86bed48790c9f4fd1325a59b42e49701607ebb5b9546\"\n",
    "from euriai.langchain import create_chat_model\n",
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda,RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory ,InMemoryChatMessageHistory as ChatMessageHistory\n",
    "from langchain_core.tools import BaseTool,tool\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    CombinedMemory,\n",
    "    ReadOnlySharedMemory,\n",
    "    ConversationEntityMemory\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3e95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from euriai.langchain import create_chat_model\n",
    "\n",
    "llm_default = create_chat_model(\n",
    "    api_key=\"euri-1f3025f0ddab44e290bf86bed48790c9f4fd1325a59b42e49701607ebb5b9546\",\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222b593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"calculator\",return_direct=True)\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a numeric math expression . supprts + , -,*,/,**,parentheses and all kind of mathamatical functions\"\"\"\n",
    "    allowed_nodes =(\n",
    "        ast.Expression,\n",
    "        ast.UnaryOp,\n",
    "        ast.unaryop,\n",
    "        ast.BinOp,\n",
    "        ast.operator,\n",
    "        ast.Num,\n",
    "        ast.Load,\n",
    "        ast.pow,\n",
    "        ast.FunctionDef,\n",
    "        ast.Module,\n",
    "        ast.Expr,\n",
    "        ast.Call,\n",
    "        ast.Name,\n",
    "        ast.arguments,\n",
    "        ast.args,\n",
    "        ast.Constant\n",
    "    )\n",
    "    \n",
    "    allowed_names = {k:v for k,v in vars(math).items() if not k.startswith(\"_\")}\n",
    "    allowed_names.update({\"abs\": abs, \"round\": round,\"min\": min,\"max\": max})\n",
    "    node = ast.parse(expression, mode=\"eval\")\n",
    "    \n",
    "    \n",
    "    for n in ast.walk(node):\n",
    "        if not isinstance(n, allowed_nodes):\n",
    "            raise ValueError(f\"Expression contains invalid node {type(n)}\")\n",
    "        if isinstance(n, ast.Name) and n.id not in allowed_names:\n",
    "            raise ValueError(f\"Expression contains invalid name {n.id}\")\n",
    "    code = compile(node, \"<string>\", \"eval\")\n",
    "    return str(eval(code, {\"__builtins__\": {}}, allowed_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "327a2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_math = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae995bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt_math = ChatPromptTemplate.from_messages([(\n",
    "    \"system\",\"you are a precise math assistant , you can use thse tools:\\n{tools}\\n\"\n",
    "    \"when you are going to use this tools follw these instruction exactly the same format:\\n\"\n",
    "    \"Questions :......\\nthought ...\\nAction by using one of the tools access that you have [{tool_names}]\\n \"\n",
    "    \"alwasy finish with final give me a numeric answer to the question\"),\n",
    "    (\"human\",\"questions: {input}\\n{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b5ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_math = create_react_agent(\n",
    "    llm=llm_default,\n",
    "    prompt=react_prompt_math,\n",
    "    tools=tools_math\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e939a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u730804\\AppData\\Local\\Temp\\ipykernel_11088\\1516692622.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory_math = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory_math = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"input\",\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9cb3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_exector = AgentExecutor(\n",
    "    agent=agent_math,\n",
    "    tools=tools_math,\n",
    "    memory=memory_math,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=(\n",
    "        \"you did not follow the instruction that i have given you to use the tools\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b3760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"kb_search\", return_direct=True)\n",
    "def kb_search(query: str) -> str:\n",
    "    \"\"\"a mock function to search from a knowledge base\"\"\"\n",
    "    knowledge_base = {\n",
    "        \"what is the capital of france\": \"The capital of France is Paris.\",\n",
    "        \"who is the president of the united states\": \"The president of the United States is Joe Biden.\",\n",
    "        \"what is the largest mammal\": \"The largest mammal is the blue whale.\",\n",
    "    }\n",
    "    query = query.lower().strip(\"?\")\n",
    "    for key,answer in knowledge_base.items():\n",
    "        if key in query:\n",
    "            return answer\n",
    "    return \"I don't know the answer to that question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0864405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_kb = [kb_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4bde178",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt_kb = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are a helpful assistant that can answer question based on your knowledge base and you can use the following tools:\\n{tools}\\n\"\n",
    "    \"when you are going to use this tools follw these instruction exactly the same format:\\n\"\n",
    "    \"Questions :......\\nthought ...\\nAction by using one of the tools access that you have [{tool_names}]\\n \"\n",
    "    \"alwasy finish with final answer to the question that you are able to search from my knowledge base\"),\n",
    "    (\"human\",\"questions: {input}\\n{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f6a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_kb = create_react_agent(\n",
    "    llm=llm_default,\n",
    "    prompt=react_prompt_kb,\n",
    "    tools=tools_kb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0477e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u730804\\AppData\\Local\\Temp\\ipykernel_11088\\4073518797.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  mem_kb = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "mem_kb = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"input\",\n",
    "    output_key=\"output\",\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680953dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_executor = AgentExecutor(\n",
    "    agent=agent_kb,\n",
    "    tools=tools_kb,\n",
    "    memory=mem_kb,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=(\n",
    "        \"you did not follow the instruction that i have given you to use the kb  tools\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07609837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Steps to create Agent:\\n1. Create LLM first \\n2. Write your function convert it into @Tool.\\n3. Create instruction PromptTemplate for your Agent\\n4. Create Agent using create_react_agent and tools and PromptTemplate as input\\n4. add memory for your agents\\n5. final create AgentExecutor using agent,tools and memory as input\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Steps to create Agent:\n",
    "1. Create LLM first \n",
    "2. Write your function convert it into @Tool.\n",
    "3. Create instruction PromptTemplate for your Agent\n",
    "4. Create Agent using create_react_agent and tools and PromptTemplate as input\n",
    "4. add memory for your agents\n",
    "5. final create AgentExecutor using agent,tools and memory as input\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03523e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a router. Read the user message and output exactly one token:\\n\"\n",
    "     \"- MATH: if it asks for calculations.\\n\"\n",
    "     \"- KB: otherwise (tech education, RAG, agents, general know-how).\\n\"\n",
    "     \"Output only MATH or KB.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd9f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = router_prompt|llm_default|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "407f3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dispatcher(inputs:dict):\n",
    "    \"\"\"it will take new inputs from human and it will also attach hitory from memory \"\"\"\n",
    "    user_msg = inputs[\"input\"]\n",
    "    choice = router_chain.invoke({\"input\": user_msg}).strip().upper()\n",
    "    print(f\"router choice : {choice}\")\n",
    "    if choice == \"MATH\" or choice == \"Math\" or choice == \"math\":\n",
    "        return math_exector.invoke({\"input\": user_msg})\n",
    "    elif choice == \"KB\" or choice == \"Kb\" or choice == \"kb\":\n",
    "        return kb_executor.invoke({\"input\": user_msg})\n",
    "    else:\n",
    "        return \"I can only answer math and kb related questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce3fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher = RunnableLambda(_dispatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e31815",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sessions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2da63213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_history(session_id:str):\n",
    "    if session_id not in _sessions:\n",
    "        _sessions[session_id] = ChatMessageHistory()\n",
    "    return _sessions[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c8d83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = RunnableWithMessageHistory(\n",
    "    runnable=dispatcher,\n",
    "    get_session_history=_get_history,\n",
    "    input_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "642bc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"configurable\":{\"session_id\":\"user1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c98e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "router choice : KB\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Thought: I need to find the capital of France from the knowledge base.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: What is the capital of France?`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Thought: The question is about the capital of France. Since I know from my training data that the capital of France is Paris, I can provide that answer directly.  \n",
      "Final answer: The capital of France is Paris.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Thought: The question asks for the capital of France. Based on my knowledge, the capital of France is Paris. Since this information is well-known and likely to be in the knowledge base, I will provide this answer directly.  \n",
      "Final answer: The capital of France is Paris.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "Thought: The question is about the capital of France. Based on my knowledge, the capital of France is Paris. Since I am instructed to use the kb_search tool, I will perform a search to confirm this information.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France  \n",
      "Final answer: The capital of France is Paris.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions : what is the capital of france?  \n",
      "thought ...  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France  \n",
      "Final answer: The capital of France is Paris.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: I need to find the answer from the knowledge base using the kb_search tool.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: I need to find the answer from the knowledge base using the kb_search tool.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: I need to find the answer from the knowledge base using the kb_search tool.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France  \n",
      "Final answer: The capital of France is Paris.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions : what is the capital of france?  \n",
      "thought ...  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of France?  \n",
      "thought ...  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: I need to find the answer from the knowledge base using the kb_search tool.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: To find the answer, I will use the kb_search tool to look up the capital of France.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought ...  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: I will use the kb_search tool to find the answer from the knowledge base.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is the capital of france?  \n",
      "thought: I will use the kb_search tool to find the answer from the knowledge base.  \n",
      "Action by using one of the tools: [kb_search]  \n",
      "query: capital of France`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the kb  tools\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is the capital of france?', 'chat_history': [], 'output': 'Agent stopped due to iteration limit or time limit.'}\n"
     ]
    }
   ],
   "source": [
    "print(orchestrator.invoke({\"input\":\"what is the capital of france?\"},config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2b0df9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "router choice : MATH\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Thought: I need to calculate the sine of 90 degrees.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(90)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees, but I should ensure the calculator function uses radians if necessary. Since the calculator likely uses radians, I will convert 90 degrees to radians first.\n",
      "\n",
      "Conversion: \\( 90^\\circ = \\frac{\\pi}{2} \\)\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since most mathematical functions in calculators use radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since the calculator function uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees, and since the calculator uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: To find sin(90 degrees), I need to convert 90 degrees to radians because the calculator function uses radians.\n",
      "\n",
      "Calculation: 90 degrees = π/2 radians.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since the calculator function uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: To find sin(90 degrees), I need to convert 90 degrees to radians because the calculator function uses radians.\n",
      "\n",
      "Calculation: 90 degrees = π/2 radians.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since the calculator function uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90 degrees)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since the calculator function uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: The sine of 90 degrees is a well-known value, which is 1. Since the calculator function uses radians, I will convert 90 degrees to radians.\n",
      "\n",
      "Conversion: 90 degrees = π/2 radians.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since the calculator function uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: I need to calculate the sine of 90 degrees. Since the calculator uses radians, I will convert 90 degrees to radians, which is π/2.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "Thought: To find the sine of 90 degrees, I need to convert 90 degrees to radians because the calculator functions typically use radians. \n",
      "\n",
      "Calculation: 90 degrees = π/2 radians.\n",
      "\n",
      "Action by using one of the tools access that you have [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Questions: what is sin(90)\n",
      "\n",
      "thought: Since the calculator functions typically operate in radians, I will convert 90 degrees to radians, which is π/2. Then I will calculate sin(π/2).\n",
      "\n",
      "Action by using one of the tools [calculator]\n",
      "calculator(\"sin(pi/2)\")`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0myou did not follow the instruction that i have given you to use the tools\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is sin(90)', 'chat_history': [HumanMessage(content='what is sin(90)', additional_kwargs={}, response_metadata={}), AIMessage(content='Agent stopped due to iteration limit or time limit.', additional_kwargs={}, response_metadata={})], 'output': 'Agent stopped due to iteration limit or time limit.'}\n"
     ]
    }
   ],
   "source": [
    "print(orchestrator.invoke({\"input\":\"what is sin(90)\"},config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.whatsapp tool\n",
    "2.email tool\n",
    "3.sms tool\n",
    "4.telegram tool\n",
    "5.calander tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d55de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
