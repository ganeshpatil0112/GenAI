# Simple H100 Dockerfile - Uses system Python
FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-venv \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create symbolic link for python
RUN ln -s /usr/bin/python3 /usr/bin/python

# Install PyTorch with CUDA 12.1 support
RUN pip3 install --upgrade pip
RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Copy requirements
COPY requirements.txt .
COPY requirements_api.txt .

# Install Python packages
RUN pip3 install -r requirements.txt
RUN pip3 install -r requirements_api.txt

# Copy application code
COPY api_server.py .
COPY finetuning/ ./finetuning/
COPY datasets/ ./datasets/

# Create models directory
RUN mkdir -p models

# Expose API port
EXPOSE 8000

# Set H100 environment variables
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTORCH_ALLOC_CONF=max_split_size_mb:512
ENV TOKENIZERS_PARALLELISM=false
ENV NCCL_P2P_DISABLE=1
ENV NCCL_IB_DISABLE=1

# Run the API server
CMD ["python3", "api_server.py"]
